{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Caso de estudio\n",
        "Para mi caso de estudio elegí el caso de entrenar multiples regresiones lineales. Elegí este caso porque a veces cuando no conocemos el modelo que mejor predice algún fenómeno entrenamos muchos modelos a veces con distintos parámetros y realizamos una evaluación cruzada para elegir el mejor modelo basándonos en esta evaluación.\n",
        ""
      ],
      "metadata": {
        "id": "mJancz8UHFZh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDw2nH2PwIlD",
        "outputId": "90ca4362-de69-4501-f98c-ec5fa6467160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución secuencial: 0.25035643577575684 segundos\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "# Cargamos el dataset California Housing\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Entrenamos múltiples modelos secuencialmente\n",
        "def entrenar_modelo_secuencial(X, y, num_modelos=1500000):\n",
        "    modelos = []\n",
        "    for i in range(num_modelos):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "        modelo = LinearRegression().fit(X_train, y_train)\n",
        "        modelos.append(modelo)\n",
        "    return modelos\n",
        "\n",
        "# Medimos el tiempo de ejecución secuencial\n",
        "start_time = time.time()\n",
        "modelos_secuenciales = entrenar_modelo_secuencial(X, y, num_modelos=5)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Tiempo de ejecución secuencial:\", end_time - start_time, \"segundos\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La porción anterior del código se ejecutó de manera secuencial, es decir, cada modelo se entrenaba uno detrás de otro. El proceso tardó 0.25 segundos, esto fue muy rápido porque la tarea en esta cantidad sigue siendo simple entonces que se resuelva de manera directa puede ser efectivo."
      ],
      "metadata": {
        "id": "qSNDGqLvMURD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWW8IogVwIlJ",
        "outputId": "783d59cc-b080-4ab4-edcc-5d5084fa5c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución con multi-hilos: 0.24039816856384277 segundos\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "\n",
        "# Función para entrenar un modelo en un hilo\n",
        "def entrenar_modelo_hilos(X, y, resultado, indice):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    modelo = LinearRegression().fit(X_train, y_train)\n",
        "    resultado[indice] = modelo\n",
        "\n",
        "# Entrenamos múltiples modelos usando hilos\n",
        "def entrenar_modelos_con_hilos(X, y, num_modelos=1500000):\n",
        "    resultados = [None] * num_modelos\n",
        "    hilos = []\n",
        "\n",
        "    for i in range(num_modelos):\n",
        "        hilo = threading.Thread(target=entrenar_modelo_hilos, args=(X, y, resultados, i))\n",
        "        hilos.append(hilo)\n",
        "        hilo.start()\n",
        "\n",
        "    # Esperamos a que todos los hilos terminen\n",
        "    for hilo in hilos:\n",
        "        hilo.join()\n",
        "\n",
        "    return resultados\n",
        "\n",
        "# Medimos el tiempo de ejecución con hilos\n",
        "start_time = time.time()\n",
        "modelos_hilos = entrenar_modelos_con_hilos(X, y, num_modelos=5)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Tiempo de ejecución con multi-hilos:\", end_time - start_time, \"segundos\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La porción de código anterior ejecuta de manera concurrente con multi-hilos, lamentablemente, es importante especificar que python obedece el GIL, lo que significa que para el multihilos solo tiene como recurso un núcleo, limitando el poder de procesamiento de la tarea. Se ejecutó en 0.24 que es ligeramente más rápido que entrenar los modelos de manera secuencial, esto porque aunque solo lo haga con un núcleo, sí se ejecuta con múltiples hilos y esto fue efectivo en este caso."
      ],
      "metadata": {
        "id": "mNTMFT2FTxIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaoeAE2mwIlL",
        "outputId": "a4bb5092-2242-49f4-9ccb-94cc05edbc56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución con multi-procesos: 0.5181884765625 segundos\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Función para entrenar un modelo en un proceso\n",
        "def entrenar_modelo_proceso(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    modelo = LinearRegression().fit(X_train, y_train)\n",
        "    return modelo\n",
        "\n",
        "# Entrenamos múltiples modelos usando procesos\n",
        "def entrenar_modelos_con_procesos(X, y, num_modelos=1500000):\n",
        "    with multiprocessing.Pool(processes=num_modelos) as pool:\n",
        "        resultados = pool.starmap(entrenar_modelo_proceso, [(X, y) for _ in range(num_modelos)])\n",
        "    return resultados\n",
        "\n",
        "# Medimos el tiempo de ejecución con procesos\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "    modelos_procesos = entrenar_modelos_con_procesos(X, y, num_modelos=5)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(\"Tiempo de ejecución con multi-procesos:\", end_time - start_time, \"segundos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta última parte de código se ejecutó de manera concurrente con múltiples procesos, la ventaja de este efoque es que no importa el GIL, de esta manera al crear más procesos sí se pueden procesar con múltiples núcleos, lo que significa que al procesar es más efectivo, sin embargo, hacer los nuevos procesos toma recursos que hacen que el tiempo de ejecución sea más lento, lo que hace que esta porción sea la más lenta de ejecutar."
      ],
      "metadata": {
        "id": "ZguJ_YwwaX4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusión\n",
        "El enfoque más efectivo fue el de multi-hilos, sin embargo, es importante notar que la diferencia entre este enfoque y el secuencial fue muy poca, lo que nos habla de que probablemente es una tarea básica en la que el tiempo \"extra\" que requiere ejecutar el problema con concurrencia no vale la pena debido a que la resolución directa del problema es lo suficientemente rápida. Esto también es verdad para cuando se ejecuta con el enfoque de multiproceso ya que en ese caso generar los procesos toma muchos recursos y tarda mucho tiempo. Así concluyo que el problema es muy sencillo y por eso el enfoque más rápido fue el secuencial.\n"
      ],
      "metadata": {
        "id": "eDj5IIFzc3X6"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}